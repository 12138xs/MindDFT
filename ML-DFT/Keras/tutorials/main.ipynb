{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精度对齐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def load_txt(file):\n",
    "    data = np.loadtxt(file)\n",
    "    return data\n",
    "\n",
    "def read_chgcar_density(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    # VASP 文件的头部信息\n",
    "    scale_factor = float(lines[1].strip())\n",
    "    # 读取晶格矢量\n",
    "    lattice_vectors = np.array([list(map(float, line.split())) for line in lines[2:5]])\n",
    "    # 读取原子类型和数量\n",
    "    atom_types = lines[5].split()\n",
    "    atom_counts = list(map(int, lines[6].split()))\n",
    "    total_atoms = sum(atom_counts)\n",
    "    # 读取密度数据的起始行\n",
    "    density_start_line = 9 + total_atoms\n",
    "    # 读取密度网格信息\n",
    "    grid_size = list(map(int, lines[density_start_line].split()))\n",
    "    nx, ny, nz = grid_size\n",
    "    # 读取密度数据\n",
    "    density_data = []\n",
    "    for line in lines[density_start_line + 1:]:\n",
    "        density_data.extend(map(float, line.split()))\n",
    "    # 将密度数据转换为三维数组\n",
    "    density_array = np.array(density_data)\n",
    "    return density_array\n",
    "\n",
    "def extract_float_from_text(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    floats = re.findall(r'\\d+\\.\\d+', text)\n",
    "    floats = [float(f) for f in floats]\n",
    "    return floats[:-3]\n",
    "\n",
    "def compute_error(data1, data2):\n",
    "    # compute the mae and relative mae\n",
    "    mae = np.mean(np.abs(data1 - data2))\n",
    "    rmae = mae / np.mean(np.abs(data1))\n",
    "    return mae, rmae\n",
    "\n",
    "def list_files(path, cmp_path):\n",
    "    chg_atoms = [r'^C_charges.*', r'^H_charges.*', r'^N_charges.*', r'^O_charges.*', r'^DOS.*']\n",
    "    tf_path = os.path.join('./tutorials', path)\n",
    "    ms_path = os.path.join(cmp_path, path)\n",
    "\n",
    "    files = os.listdir(tf_path)\n",
    "    for chg_atom in chg_atoms:\n",
    "        for file in files:\n",
    "            if re.match(chg_atom, file):\n",
    "                tf_chg = load_txt(os.path.join(tf_path, file))\n",
    "                ms_chg = load_txt(os.path.join(ms_path, file))\n",
    "                mae, rmae = compute_error(tf_chg, ms_chg)\n",
    "                print(f'[{chg_atom[1:4]}] {file.split(\"_\")[-1].split(\".\")[0][:10]:10}: MAE={mae:2.8f}, RMAE={rmae:2.8f}')\n",
    "    \n",
    "    for file in files:\n",
    "        if re.match(r'^Pred_CHG.*', file):\n",
    "            tf_chg = read_chgcar_density(os.path.join(tf_path, file))\n",
    "            ms_chg = read_chgcar_density(os.path.join(ms_path, file))\n",
    "            mae, rmae = compute_error(tf_chg, ms_chg)\n",
    "            print(f'[CHG] {file.split(\"_\")[-1].split(\".\")[0][:10]:10}: MAE={mae:2.8f}, RMAE={rmae:2.8f}')\n",
    "\n",
    "    if path[:2] == 'T1':\n",
    "        tf_floats = extract_float_from_text(os.path.join(tf_path, 'OUT_DATA.log'))\n",
    "        ms_floats = extract_float_from_text(os.path.join(ms_path, 'OUT_DATA.log'))\n",
    "        mae, rmae = compute_error(np.array(tf_floats), np.array(ms_floats))\n",
    "        print(f'[OUT]           : MAE={mae:2.8f}, RMAE={rmae:2.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_stdout = sys.stdout\n",
    "f = open('KerasVSpynative.log', 'w')\n",
    "sys.stdout = f\n",
    "\n",
    "paths = [\n",
    "    \"T1_Predicting_CHG_E_DOS\",\n",
    "    \"T1_Predicting_CHG_E_DOS_ALL\",\n",
    "    \"T2_Train_EFP\",\n",
    "    \"T3_Train_DOS\"\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    print(\"========================================{:30}========================================\".format(path))\n",
    "    list_files(path, '../ML-DFT-ms39/PYNATIVE/tutorials')\n",
    "    print(\"\\n\")\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_stdout = sys.stdout\n",
    "f = open('KerasVSgraph.log', 'w')\n",
    "sys.stdout = f\n",
    "\n",
    "paths = [\n",
    "    \"T1_Predicting_CHG_E_DOS\",\n",
    "    \"T1_Predicting_CHG_E_DOS_ALL\",\n",
    "    \"T2_Train_EFP\",\n",
    "    \"T3_Train_DOS\"\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    print(\"========================================{:30}========================================\".format(path))\n",
    "    list_files(path, '../ML-DFT-ms39/GRAPH/tutorials')\n",
    "    print(\"\\n\")\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.00543830e+00 4.00825170e+00 3.99982380e+00 4.00722270e+00\n",
      " 4.00700140e+00 4.00096270e+00 9.82319240e-01 9.81335640e-01\n",
      " 9.81985330e-01 9.82557300e-01 9.83064800e-01 9.82784100e-01\n",
      " 7.57137051e+01 5.58588450e-01 4.59736620e-01 2.81325550e-01\n",
      " 1.30061450e+00 6.47097350e-01 4.92146000e-01 2.02789740e+00\n",
      " 4.86163600e-01 1.04766420e+00 1.89562510e+00 1.98968280e+00\n",
      " 6.15723000e-01 3.10548110e+00 7.44978850e-01 1.51498580e+00\n",
      " 1.27760160e+00 9.15084400e-02 5.36115200e-01 2.62290450e-01\n",
      " 5.61034000e-01 2.86039860e-01 7.69326270e-01 3.73211500e-01\n",
      " 2.89164750e-01 2.39248200e-01 1.54484400e-01 1.15564200e-01\n",
      " 1.98507770e-01 2.39390160e-01 6.90811400e-02 1.30469820e+00\n",
      " 1.01904190e+00 1.70750920e-01 1.28440010e-01 2.21347560e-01\n",
      " 3.46651600e-02 4.62489650e+00 4.33167270e+00 1.68412070e+00\n",
      " 7.38772000e-01 4.18175580e-01 2.27746300e+00 6.23646688e+00\n",
      " 1.57894570e-02 1.33203185e+00 1.65031250e-02 4.90443504e+00\n",
      " 2.45868170e-02 2.99227392e+01 1.27083724e+00 1.17011126e+02]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def extract_floats_from_text(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # 使用正则表达式匹配所有浮点数（包含小数点的数字）\n",
    "    floats = re.findall(r'\\d+\\.\\d+', text)\n",
    "    \n",
    "    # 将匹配的数字转换为浮点数\n",
    "    floats = [float(num) for num in floats]\n",
    "    \n",
    "    return floats\n",
    "\n",
    "# 示例使用\n",
    "file_path = './tutorials/T1_Predicting_CHG_E_DOS/OUT_DATA'\n",
    "floats_array = extract_floats_from_text(file_path)\n",
    "floats_array = np.array(floats_array)\n",
    "print(floats_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x7f68145be790>\n",
      "[[[0.06014159]\n",
      "  [0.64984425]\n",
      "  [0.36385862]]]\n",
      "[array([[[-0.03125644,  0.09805012]],\n",
      "\n",
      "       [[ 0.33049035,  0.12989593]]], dtype=float32), array([0., 0.], dtype=float32)]\n",
      "[[[0.21288744 0.09030901]\n",
      "  [0.09993994 0.11098105]]]\n",
      "(1, 3, 1)\n",
      "(2, 1, 2) (2,)\n",
      "(1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, Input\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "\n",
    "def test_model():\n",
    "    input = Input(shape=(3, 1))\n",
    "    cov = Conv1D(2,kernel_size=2,activation='relu')(input)\n",
    "    net = Model(inputs=input, outputs=cov)\n",
    "    return net\n",
    "\n",
    "net = test_model()\n",
    "print(net)\n",
    "random_input = np.random.rand(1,3,1)\n",
    "output = net.predict(random_input)\n",
    "print(random_input)\n",
    "print(net.layers[1].get_weights())\n",
    "print(output)\n",
    "print(random_input.shape)\n",
    "print(net.layers[1].get_weights()[0].shape, net.layers[1].get_weights()[1].shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.0001429] [1.        1.0001761] [1.        1.0001429] [1.        1.0001429] [1.] [1.        1.0002934] [1.        1.0002934] [1.        1.0002934] [1.        1.0002934]\n",
      "(1, 341) (341,) -0.0 0.0 -54.09758377075195 0.0 -54.09758377075195 0.0\n",
      "[0.         0.         0.         0.         0.03025112]\n",
      "[118.314804 164.45445  201.31795  165.51218  113.63244 ]\n",
      "0.0\n",
      "307.36807\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from DOS import init_DOSmod\n",
    "import tensorflow as tf\n",
    "\n",
    "net = init_DOSmod(10)\n",
    "net.load_weights('../Trained_models/weights_DOS.hdf5')\n",
    "\n",
    "input1 = np.linspace(1,2,700*10).reshape(10,700).astype(np.float32)\n",
    "input2 = np.linspace(1,2,568*10).reshape(10,568).astype(np.float32)\n",
    "input3 = np.linspace(1,2,700*10).reshape(10,700).astype(np.float32)\n",
    "input4 = np.linspace(1,2,700*10).reshape(10,700).astype(np.float32)\n",
    "input5 = np.array([1]).astype(np.float32)\n",
    "input6 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "input7 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "input8 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "input9 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "print(input1[0,:2], input2[0,:2], input3[0,:2], input4[0,:2], input5, input6[0,:2], input7[0,:2], input8[0,:2], input9[0,:2])\n",
    "\n",
    "inputs = [input1, input2, input3, input4, input5, input6, input7, input8, input9]\n",
    "inputs = [np.expand_dims(i, axis=0) for i in inputs]\n",
    "\n",
    "resultD = []\n",
    "resultvbcb=[]\n",
    "for i in range(1):\n",
    "    Pred,vbcb=net.predict(inputs, batch_size=1)\n",
    "    resultD.append(Pred*inputs[4])\n",
    "    resultvbcb.append(vbcb)\n",
    "resultD=np.array(resultD)\n",
    "Pred = resultD.mean(axis=0)\n",
    "resultvbcb=np.array(resultvbcb)\n",
    "devVB=resultvbcb.std(axis=0)[0][0]\n",
    "devCB=resultvbcb.std(axis=0)[0][1]\n",
    "Pred_vb =(-1)*resultvbcb.mean(axis=0)[0][0]\n",
    "Pred_cb =(-1)*resultvbcb.mean(axis=0)[0][1]\n",
    "uncertainty = resultD.std(axis=0)\n",
    "uncertainty=np.squeeze(uncertainty)\n",
    "resultvbcb=np.vstack(resultvbcb)\n",
    "Bandgap=Pred_cb-Pred_vb\n",
    "devBG=resultvbcb[:,0]-resultvbcb[:,1]\n",
    "devBG=devBG.std(axis=0)\n",
    "\n",
    "print(Pred.shape, uncertainty.shape, Pred_vb, devVB, Pred_cb, devCB, Bandgap, devBG)\n",
    "print(Pred[0,:5], Pred[0,-5:], np.min(Pred), np.max(Pred), sep='\\n')\n",
    "\n",
    "#print(Pred, uncertainty,Pred_vb,devVB,Pred_cb,devCB,Bandgap,devBG)\n",
    "# print(Pred[0,:5], uncertainty[:5], Pred_vb, devVB, Pred_cb, devCB, Bandgap, devBG, sep='\\n')\n",
    "# print(np.min(Pred), np.max(Pred), np.min(uncertainty), np.max(uncertainty), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda,Input, concatenate,Dense,Reshape, Conv1D,Activation, Add, ReLU, TimeDistributed,Dropout\n",
    "from keras.models import load_model\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "padding_size=10\n",
    "\n",
    "def init_DOSmod(padding_size):\n",
    "    def dos_model():\n",
    "        def single_atom_modelC_1():\n",
    "            model_input=Input(shape=(700,))\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_input)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(343,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Reshape((343,-1))(model_out)\n",
    "            model_out=Conv1D(3,kernel_size=3,activation='relu')(model_out)\n",
    "            model_out=Lambda(lambda x: tf.keras.backend.mean(x,axis=-1))(model_out)\n",
    "            model=Model(inputs=model_input, outputs=model_out)\n",
    "            return model\n",
    "        def single_atom_modelH_1():\n",
    "            model_input=Input(shape=(568,))\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_input)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(343,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Reshape((343,-1))(model_out)\n",
    "            model_out=Conv1D(3,kernel_size=3,activation='relu')(model_out)\n",
    "            model_out=Lambda(lambda x: tf.keras.backend.mean(x,axis=-1))(model_out)\n",
    "            model=Model(inputs=model_input, outputs=model_out)\n",
    "            return model\n",
    "        def single_atom_modelN_1():\n",
    "            model_input=Input(shape=(700,))\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_input)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(343,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Reshape((343,-1))(model_out)\n",
    "            model_out=Conv1D(3,kernel_size=3,activation='relu')(model_out)\n",
    "            model_out=Lambda(lambda x: tf.keras.backend.mean(x,axis=-1))(model_out)\n",
    "            model=Model(inputs=model_input, outputs=model_out)\n",
    "            return model\n",
    "        def single_atom_modelO_1():\n",
    "            model_input=Input(shape=(700,))\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_input)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Dense(343,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "            model_out=Reshape((343,-1))(model_out)\n",
    "            model_out=Conv1D(3,kernel_size=3,activation='relu')(model_out)\n",
    "            model_out=Lambda(lambda x: tf.keras.backend.mean(x,axis=-1))(model_out)\n",
    "            model=Model(inputs=model_input, outputs=model_out)\n",
    "            return model\n",
    "        input1=Input(shape=(padding_size,700))\n",
    "        input2=Input(shape=(padding_size,568))\n",
    "        input3=Input(shape=(padding_size,700))\n",
    "        input4=Input(shape=(padding_size,700))\n",
    "        input5=Input(shape=(1,))\n",
    "        input6=Input(shape=(padding_size,341))\n",
    "        input7=Input(shape=(padding_size,341))\n",
    "        input8=Input(shape=(padding_size,341))\n",
    "        input9=Input(shape=(padding_size,341))\n",
    "        model_out_C1=TimeDistributed(single_atom_modelC_1(),name='atom_dosC_1')(input1)\n",
    "        model_out_H1=TimeDistributed(single_atom_modelH_1(),name='atom_dosH_1')(input2)\n",
    "        model_out_N1=TimeDistributed(single_atom_modelN_1(),name='atom_dosN_1')(input3)\n",
    "        model_out_O1=TimeDistributed(single_atom_modelO_1(),name='atom_dosO_1')(input4)\n",
    "        D_C=Lambda(lambda x: tf.math.multiply(x[0],x[1]),name='D_C')([input6,model_out_C1])\n",
    "        D_H=Lambda(lambda x: tf.math.multiply(x[0],x[1]),name='D_H')([input7,model_out_H1])\n",
    "        D_N=Lambda(lambda x: tf.math.multiply(x[0],x[1]),name='D_N')([input8,model_out_N1])\n",
    "        D_O=Lambda(lambda x: tf.math.multiply(x[0],x[1]),name='D_O')([input9,model_out_O1])\n",
    "        model_added1=Add()([D_C,D_H,D_N,D_O])\n",
    "\n",
    "        model_s1=Lambda(lambda x: tf.keras.backend.sum(x,axis=1))(model_added1)\n",
    "        model_dos=Lambda(lambda x: x/input5,name='DOS1')(model_s1)\n",
    "        bands=Dense(100,activation='relu',activity_regularizer=l2(0.01))(model_dos)\n",
    "        bands=Dense(100,activation='relu',activity_regularizer=l2(0.01))(bands)\n",
    "        bands=Dense(2,activation='relu')(bands)\n",
    "        model= Model(inputs=[input1,input2,input3,input4,input5,input6,input7,input8,input9], outputs=[model_dos,bands])\n",
    "        opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "        model.compile(loss=\"mean_squared_error\",optimizer=opt,loss_weights=[1000,1])\n",
    "\n",
    "        return model\n",
    "    modelDOS=dos_model()\n",
    "    return modelDOS\n",
    "\n",
    "model = init_DOSmod(padding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.0001429] [1.        1.0001761] [1.        1.0001429] [1.        1.0001429] [1.] [1.        1.0002934] [1.        1.0002934] [1.        1.0002934] [1.        1.0002934]\n",
      "[array([[ 7.92782   ,  3.392028  ,  1.8162076 ,  6.0736217 ,  4.697298  ,\n",
      "         3.3485682 ,  7.9982214 ,  4.410218  ,  6.67941   ,  5.3119183 ,\n",
      "         6.7439604 ,  1.4122567 ,  9.527989  ,  2.6138964 ,  7.508136  ,\n",
      "         0.7062812 ,  2.3905354 ,  2.6121025 ,  5.6294293 ,  2.1034234 ,\n",
      "         3.0660615 ,  3.2437024 ,  3.115258  ,  1.3584677 ,  2.2491052 ,\n",
      "         1.0826668 ,  2.6484418 ,  1.9205368 ,  3.6130838 ,  7.411451  ,\n",
      "         5.312133  ,  8.841053  ,  6.206501  ,  3.373712  ,  3.9756603 ,\n",
      "         4.765744  ,  3.8590481 ,  9.224546  ,  6.767336  ,  3.533239  ,\n",
      "         3.7462835 ,  0.9238925 ,  0.21277952,  2.950078  ,  2.5659664 ,\n",
      "         4.6525583 ,  5.1969876 ,  9.347906  ,  4.959262  ,  3.6720457 ,\n",
      "         3.9378092 ,  4.858216  ,  3.7078404 ,  4.5242176 ,  3.3074877 ,\n",
      "         1.831768  ,  5.271077  ,  5.7431436 ,  6.108222  ,  9.957094  ,\n",
      "         4.226342  ,  7.2160716 ,  3.7407722 ,  6.3939366 ,  2.3872318 ,\n",
      "         1.6232202 ,  2.5111141 ,  1.4024363 ,  2.021819  ,  2.3530548 ,\n",
      "         0.3272422 ,  2.5564942 ,  4.364447  ,  6.8517613 ,  2.7766292 ,\n",
      "         1.8197055 ,  3.5282156 ,  7.803931  ,  6.9255075 ,  6.4109592 ,\n",
      "         9.982206  ,  1.927912  ,  4.2868223 ,  1.0980498 ,  6.943372  ,\n",
      "         0.5099435 ,  2.350979  ,  1.9357697 ,  5.4989834 ,  3.9093037 ,\n",
      "         5.0267725 ,  2.6651495 ,  3.7470329 ,  1.3911217 ,  2.2231207 ,\n",
      "         2.933968  ,  9.648651  ,  4.3193827 ,  4.129676  ,  3.3492787 ,\n",
      "         8.754026  ,  4.6104646 ,  6.290936  ,  3.337369  ,  6.9146576 ,\n",
      "         5.117859  ,  9.305685  ,  4.080561  ,  6.48211   ,  2.973403  ,\n",
      "         2.243765  ,  1.2682029 ,  1.7017244 ,  3.2473373 ,  1.9763439 ,\n",
      "         2.42273   ,  4.56205   ,  3.2617898 ,  6.3596582 ,  2.0764048 ,\n",
      "         5.6316357 ,  2.887487  ,  0.43590093,  2.3184888 ,  0.8318367 ,\n",
      "         6.8381443 ,  3.8749995 ,  2.2870123 ,  3.1463065 ,  5.1333847 ,\n",
      "         4.8265877 ,  7.9248056 ,  3.4274688 ,  7.1446114 ,  1.4296787 ,\n",
      "         1.128586  ,  2.674418  ,  0.37327728,  7.2183285 ,  4.144693  ,\n",
      "         7.0570474 ,  4.83585   ,  5.51135   ,  1.2697061 ,  2.9993124 ,\n",
      "         2.4900172 ,  8.773635  ,  8.523473  ,  9.705548  ,  7.815385  ,\n",
      "         7.0004787 ,  6.540922  ,  1.438225  ,  1.8193951 ,  1.5532508 ,\n",
      "         3.4613023 ,  2.067072  ,  2.9978828 ,  4.4141583 ,  4.5392876 ,\n",
      "         2.1831112 ,  3.1809618 ,  2.124676  ,  1.99876   ,  1.2495003 ,\n",
      "         2.2935083 ,  0.85879743,  5.501939  ,  3.7428794 ,  4.3077927 ,\n",
      "         1.9133904 ,  0.9334588 ,  0.3001527 ,  1.6655897 ,  0.        ,\n",
      "         4.767683  ,  3.9702077 ,  1.9583882 ,  3.5724587 ,  4.8879642 ,\n",
      "         2.3697288 ,  1.2048954 ,  2.8703792 ,  6.7290416 ,  6.1010118 ,\n",
      "         2.6575217 ,  4.2185044 ,  6.303091  ,  4.4183335 ,  4.906634  ,\n",
      "         5.531465  ,  2.2513068 ,  2.1819758 ,  0.92935216,  2.1042356 ,\n",
      "         1.5991776 ,  2.8809066 ,  1.9103031 ,  6.2243524 ,  4.137782  ,\n",
      "         5.686347  ,  4.8214273 ,  6.2869096 ,  8.085554  ,  4.00369   ,\n",
      "         3.8544514 ,  2.5762682 ,  3.1921537 ,  1.193336  ,  4.630247  ,\n",
      "         0.20353857,  0.8128841 ,  3.7487988 ,  3.3380833 ,  6.8420377 ,\n",
      "         4.36007   ,  1.3650755 ,  3.1263795 ,  1.561336  ,  1.8228827 ,\n",
      "         6.189688  ,  4.691606  ,  9.162017  ,  0.9671064 ,  7.334778  ,\n",
      "         7.2858768 , 11.929435  ,  8.831668  ,  3.8631177 ,  0.61450684,\n",
      "         1.8597769 ,  3.1033838 ,  5.3325872 ,  2.1989238 ,  2.9569423 ,\n",
      "         2.3533487 ,  0.5785549 ,  1.9696448 ,  0.        ,  0.8113709 ,\n",
      "         0.65208113,  2.7960668 ,  2.1477077 ,  3.5744102 ,  2.8152292 ,\n",
      "         2.3674502 ,  1.5384309 ,  4.1195703 ,  3.993122  ,  2.7371943 ,\n",
      "         2.501548  ,  4.6819525 ,  5.007361  ,  2.1481142 ,  3.0883214 ,\n",
      "         2.336689  ,  4.030918  ,  6.778407  ,  4.980459  , 12.101262  ,\n",
      "         6.1461644 ,  4.9302974 ,  6.4206448 ,  4.5586023 ,  5.324064  ,\n",
      "         1.7839173 ,  4.440704  ,  6.3300366 ,  2.0675604 ,  3.0171986 ,\n",
      "         5.9708114 ,  1.3002539 ,  2.0003185 ,  1.3761797 ,  3.5700479 ,\n",
      "         3.5189395 ,  4.0845923 ,  2.7124517 ,  2.7296083 ,  4.768156  ,\n",
      "         6.1724906 ,  5.4915023 ,  0.87992644,  4.1420846 ,  3.2811732 ,\n",
      "         5.7634406 ,  1.8102505 ,  2.338529  ,  1.6750998 ,  1.8810747 ,\n",
      "         0.05266466,  0.97693354,  0.8130595 ,  2.6010358 ,  6.2549553 ,\n",
      "         3.4387074 ,  6.089329  ,  1.5543836 ,  3.2454321 ,  2.2724543 ,\n",
      "         0.564221  ,  4.192264  ,  5.220251  ,  8.516734  ,  6.906848  ,\n",
      "         6.1593466 ,  6.5309515 ,  3.1174426 ,  4.2607317 ,  3.0682554 ,\n",
      "         2.9627557 ,  5.5703697 ,  2.8408303 ,  2.9038541 ,  1.2165574 ,\n",
      "         2.646051  ,  2.474553  ,  2.1455467 ,  0.13362622,  1.9362628 ,\n",
      "         5.2457757 ,  6.5473995 ,  3.8784828 ,  8.01179   ,  3.2170568 ,\n",
      "         5.589712  ,  5.0088806 ,  8.689579  ,  4.3692727 ,  4.5040293 ,\n",
      "         6.5813394 ,  2.110296  ,  5.4521933 ,  2.733244  ,  2.509131  ,\n",
      "         2.1760452 ,  5.0481973 ,  4.905812  ,  3.146452  ,  2.462977  ,\n",
      "         2.33944   ]], dtype=float32), array([[0.       , 5.1010957]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input1 = np.linspace(1,2,700*10).reshape(10,700).astype(np.float32)\n",
    "input2 = np.linspace(1,2,568*10).reshape(10,568).astype(np.float32)\n",
    "input3 = np.linspace(1,2,700*10).reshape(10,700).astype(np.float32)\n",
    "input4 = np.linspace(1,2,700*10).reshape(10,700).astype(np.float32)\n",
    "input5 = np.array([1]).astype(np.float32)\n",
    "input6 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "input7 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "input8 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "input9 = np.linspace(1,2,341*10).reshape(10,341).astype(np.float32)\n",
    "print(input1[0,:2], input2[0,:2], input3[0,:2], input4[0,:2], input5, input6[0,:2], input7[0,:2], input8[0,:2], input9[0,:2])\n",
    "\n",
    "inputs = [input1, input2, input3, input4, input5, input6, input7, input8, input9]\n",
    "inputs = [np.expand_dims(i, axis=0) for i in inputs]\n",
    "output = model.predict(inputs, batch_size=1)\n",
    "print(output)\n",
    "# save model\n",
    "model.save_weights('./model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 340) (1, 10, 208) (1, 10, 340) (1, 10, 340)\n",
      "[2.7545054 0.4031816 4.274326  2.321104  4.463279 ] [3.5862846 4.52964   2.848134  3.7696545 4.4418006] [3.0112755 2.9462447 3.1302595 6.373972  3.9518328] [3.1376822 6.75171   7.038846  5.9741545 6.4981647]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from CHG import init_chgmod\n",
    "import tensorflow as tf\n",
    "\n",
    "net = init_chgmod(10)\n",
    "net.load_weights('../Trained_models/weights_CHG.hdf5')\n",
    "\n",
    "input1 = np.linspace(0,1,10*360).reshape(10,360).astype(np.float32)\n",
    "input2 = np.linspace(0,1,10*360).reshape(10,360).astype(np.float32)\n",
    "input3 = np.linspace(0,1,10*360).reshape(10,360).astype(np.float32)\n",
    "input4 = np.linspace(0,1,10*360).reshape(10,360).astype(np.float32)\n",
    "\n",
    "inputs = [input1, input2, input3, input4]\n",
    "inputs = [np.expand_dims(i, axis=0) for i in inputs]\n",
    "outputs = net.predict(inputs)\n",
    "print(outputs[0].shape, outputs[1].shape, outputs[2].shape, outputs[3].shape)\n",
    "print(outputs[0][0,0,:5], outputs[1][0,0,:5], outputs[2][0,0,:5], outputs[3][0,0,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1) (1, 10, 3) (1, 10, 3) (1, 10, 3) (1, 10, 3) (1, 6)\n",
      "[98.10155]\n",
      "[-1.1681886 -1.1731949 -1.178201 ]\n",
      "[-0.04971177 -0.04997553 -0.05023931]\n",
      "[0.10500497 0.10545186 0.10589875]\n",
      "[0.36152738 0.36307415 0.36462092]\n",
      "[18721.4   18744.576 18767.768 18732.984 18756.168 18744.566]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from Energy import init_Emod\n",
    "import tensorflow as tf\n",
    "\n",
    "net = init_Emod(10)\n",
    "net.load_weights('../Trained_models/weights_EFP.hdf5')\n",
    "\n",
    "input1 = np.linspace(0,1,10*709).reshape(10,709).astype(np.float32)\n",
    "input2 = np.linspace(0,1,10*577).reshape(10,577).astype(np.float32)\n",
    "input3 = np.linspace(0,1,10*709).reshape(10,709).astype(np.float32)\n",
    "input4 = np.linspace(0,1,10*709).reshape(10,709).astype(np.float32)\n",
    "input5 = np.array([1]).astype(np.float32)\n",
    "input6 = np.linspace(0,1,10*1).reshape(10,1).astype(np.float32)\n",
    "input7 = np.linspace(0,1,10*1).reshape(10,1).astype(np.float32)\n",
    "input8 = np.linspace(0,1,10*1).reshape(10,1).astype(np.float32)\n",
    "input9 = np.linspace(0,1,10*1).reshape(10,1).astype(np.float32)\n",
    "\n",
    "inputs = [input1, input2, input3, input4, input5, input6, input7, input8, input9]\n",
    "inputs = [np.expand_dims(i, axis=0) for i in inputs]\n",
    "outputs = net.predict(inputs)\n",
    "out1,out2,out3,out4,out5,out6 = outputs\n",
    "print(out1.shape, out2.shape, out3.shape, out4.shape, out5.shape, out6.shape)\n",
    "print(out1[0], out2[0,0], out3[0,0], out4[0,0], out5[0,0], out6[0], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 600)               420600    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 600)               360600    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 600)               360600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 600)               360600    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 343)               206143    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 343, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 341, 3)            12        \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 341)               0         \n",
      "=================================================================\n",
      "Total params: 1,708,555\n",
      "Trainable params: 1,708,555\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, Reshape, Lambda, Dropout\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n",
    "def single_atom_modelC_1():\n",
    "    model_input=Input(shape=(700,))\n",
    "    model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_input)\n",
    "    model_out=Dropout(0.1)(model_out,training=True)\n",
    "    model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "    model_out=Dropout(0.1)(model_out,training=True)\n",
    "    model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "    model_out=Dropout(0.1)(model_out,training=True)\n",
    "    model_out=Dense(600,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "    model_out=Dropout(0.1)(model_out,training=True)\n",
    "    model_out=Dense(343,activation='relu',activity_regularizer=l2(0.1),kernel_initializer='glorot_uniform')(model_out)\n",
    "    model_out=Reshape((343,-1))(model_out)\n",
    "    model_out=Conv1D(3,kernel_size=3,activation='relu')(model_out)\n",
    "    model_out=Lambda(lambda x: tf.keras.backend.mean(x,axis=-1))(model_out)\n",
    "    model=Model(inputs=model_input, outputs=model_out)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = single_atom_modelC_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['DOS1', 'D_C', 'D_H', 'D_N', 'D_O', 'add_1', 'atom_dosC_1', 'atom_dosH_1', 'atom_dosN_1', 'atom_dosO_1', 'dense_41', 'dense_42', 'dense_43', 'input_10', 'input_11', 'input_12', 'input_14', 'input_15', 'input_16', 'input_17', 'input_9', 'lambda_13']>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 ['conv1d_1', 'dense_21', 'dense_22', 'dense_23', 'dense_24', 'dense_25']>\n",
      "Keys: <KeysViewHDF5 ['conv1d_2', 'dense_26', 'dense_27', 'dense_28', 'dense_29', 'dense_30']>\n",
      "Keys: <KeysViewHDF5 ['conv1d_3', 'dense_31', 'dense_32', 'dense_33', 'dense_34', 'dense_35']>\n",
      "Keys: <KeysViewHDF5 ['conv1d_4', 'dense_36', 'dense_37', 'dense_38', 'dense_39', 'dense_40']>\n",
      "Keys: <KeysViewHDF5 ['dense_41']>\n",
      "Keys: <KeysViewHDF5 ['dense_42']>\n",
      "Keys: <KeysViewHDF5 ['dense_43']>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 []>\n",
      "Keys: <KeysViewHDF5 ['bias:0', 'kernel:0']>\n",
      "Keys: <HDF5 dataset \"bias:0\": shape (3,), type \"<f4\">\n",
      "Keys: <HDF5 dataset \"kernel:0\": shape (3, 1, 3), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "filepath=\"../Trained_models/weights_DOS.hdf5\"\n",
    "with h5py.File(filepath, \"r\") as weights:\n",
    "    print(\"Keys: %s\" % weights.keys())\n",
    "    # Keys: <KeysViewHDF5 ['DOS1', 'D_C', 'D_H', 'D_N', 'D_O', 'add_1', 'atom_dosC_1', 'atom_dosH_1', 'atom_dosN_1', 'atom_dosO_1', 'dense_41', 'dense_42', 'dense_43', \n",
    "    # 'input_10', 'input_11', 'input_12', 'input_14', 'input_15', 'input_16', 'input_17', 'input_9', 'lambda_13']>\n",
    "    print(\"Keys: %s\" % weights['DOS1'].keys())\n",
    "    print(\"Keys: %s\" % weights['D_C'].keys())\n",
    "    print(\"Keys: %s\" % weights['D_H'].keys())\n",
    "    print(\"Keys: %s\" % weights['D_N'].keys())\n",
    "    print(\"Keys: %s\" % weights['D_O'].keys())\n",
    "    print(\"Keys: %s\" % weights['add_1'].keys())\n",
    "    print(\"Keys: %s\" % weights['atom_dosC_1'].keys())\n",
    "    print(\"Keys: %s\" % weights['atom_dosH_1'].keys())\n",
    "    print(\"Keys: %s\" % weights['atom_dosN_1'].keys())\n",
    "    print(\"Keys: %s\" % weights['atom_dosO_1'].keys())\n",
    "    print(\"Keys: %s\" % weights['dense_41'].keys())\n",
    "    print(\"Keys: %s\" % weights['dense_42'].keys())\n",
    "    print(\"Keys: %s\" % weights['dense_43'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_10'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_11'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_12'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_14'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_15'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_16'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_17'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_9'].keys())\n",
    "    print(\"Keys: %s\" % weights['lambda_13'].keys())\n",
    "    print(\"Keys: %s\" % weights['atom_dosC_1']['conv1d_1'].keys())\n",
    "    print(\"Keys: %s\" % weights['atom_dosC_1']['conv1d_1']['bias:0'])\n",
    "    print(\"Keys: %s\" % weights['atom_dosC_1']['conv1d_1']['kernel:0'])\n",
    "\n",
    "    # optimizer_weights = f['optimizer_weights']\n",
    "    # print(\"Keys: %s\" % optimizer_weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 700)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10, 568)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10, 700)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 10, 700)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 10, 341)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_dosC_1 (TimeDistributed)   (None, 10, 341)      1708555     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 10, 341)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_dosH_1 (TimeDistributed)   (None, 10, 341)      1629355     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 10, 341)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_dosN_1 (TimeDistributed)   (None, 10, 341)      1708555     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 10, 341)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "atom_dosO_1 (TimeDistributed)   (None, 10, 341)      1708555     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "D_C (Lambda)                    (None, 10, 341)      0           input_6[0][0]                    \n",
      "                                                                 atom_dosC_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "D_H (Lambda)                    (None, 10, 341)      0           input_7[0][0]                    \n",
      "                                                                 atom_dosH_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "D_N (Lambda)                    (None, 10, 341)      0           input_8[0][0]                    \n",
      "                                                                 atom_dosN_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "D_O (Lambda)                    (None, 10, 341)      0           input_9[0][0]                    \n",
      "                                                                 atom_dosO_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10, 341)      0           D_C[0][0]                        \n",
      "                                                                 D_H[0][0]                        \n",
      "                                                                 D_N[0][0]                        \n",
      "                                                                 D_O[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 341)          0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "DOS1 (Lambda)                   (None, 341)          0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 100)          34200       DOS1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 100)          10100       dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 2)            202         dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,799,522\n",
      "Trainable params: 6,799,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from DOS import init_DOSmod\n",
    "\n",
    "CONFIG_PATH1 = '../Trained_models/weights_DOS.hdf5'\n",
    "\n",
    "padding_size = 10\n",
    "rtmodel = init_DOSmod(padding_size)\n",
    "rtmodel.load_weights(CONFIG_PATH1)\n",
    "rtmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'D_C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_105162/3306834095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrtmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'D_C'"
     ]
    }
   ],
   "source": [
    "rtmodel.D_C.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"../Trained_models/weights_CHG.hdf5\"\n",
    "with h5py.File(filepath, \"r\") as f:\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    # Keys: <KeysViewHDF5 ['model_weights', 'optimizer_weights']>\n",
    "    weights = f['model_weights']\n",
    "    print(\"Keys: %s\" % weights.keys())\n",
    "    # Keys: <KeysViewHDF5 ['add_10', 'add_11', 'add_9', 'atomC1_chg', 'atomH1_chg', 'atomN1_chg', 'atomO1_chg', 'input_1', 'input_2', 'input_3', 'input_4', 'lambda_640', 'lambda_641', 'lambda_642', 'lambda_643']>\n",
    "    print(\"Keys: %s\" % weights['add_10'].keys())\n",
    "    print(\"Keys: %s\" % weights['add_11'].keys())\n",
    "    print(\"Keys: %s\" % weights['add_9'].keys())\n",
    "    print(\"Keys: %s\" % weights['atomC1_chg'].keys())\n",
    "    print(\"Keys: %s\" % weights['atomH1_chg'].keys())\n",
    "    print(\"Keys: %s\" % weights['atomN1_chg'].keys())\n",
    "    print(\"Keys: %s\" % weights['atomO1_chg'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_1'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_2'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_3'].keys())\n",
    "    print(\"Keys: %s\" % weights['input_4'].keys())\n",
    "    print(\"Keys: %s\" % weights['lambda_640'].keys())\n",
    "    print(\"Keys: %s\" % weights['lambda_641'].keys())\n",
    "    print(\"Keys: %s\" % weights['lambda_642'].keys())\n",
    "    print(\"Keys: %s\" % weights['lambda_643'].keys())\n",
    "    print(\"Keys: %s\" % weights['dense_22'].keys())\n",
    "\n",
    "    # optimizer_weights = f['optimizer_weights']\n",
    "    # print(\"Keys: %s\" % optimizer_weights.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看网络输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras import Model\n",
    "from keras.layers import *\n",
    "class Normal(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Normal, self).__init__(**kwargs) #必须定义的\n",
    "    def build(self, input_shape):\n",
    "        # 添加可训练的参数\n",
    "        self.kernel = self.add_weight(name='kernel',shape=(1,),\n",
    "                                      initializer='zeros',trainable=True)\n",
    "        self.built = True\n",
    "    def call(self, x):\n",
    "        # 定义功能，相当于Lambda层的功能函数\n",
    "        self.x_normalized = K.l2_normalize(x, -1)\n",
    "        return self.x_normalized * self.kernel\n",
    "\n",
    "x_in = Input(shape=(784,))\n",
    "x = x_in\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "normal = Normal()\n",
    "x = normal(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(x_in, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cenjianhuan/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 18:07:14.015716: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2024-09-13 18:07:14.053974: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz\n",
      "2024-09-13 18:07:14.069581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559327c12550 executing computations on platform Host. Devices:\n",
      "2024-09-13 18:07:14.069648: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2024-09-13 18:07:14.127356: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1, 256)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "x_test = np.ones((batch_size,)+K.int_shape(x_in)[1:])\n",
    "fn = K.function([x_in], [normal.x_normalized])\n",
    "v1 = fn([x_test])\n",
    "np.array(v1).shape ##(1,1,256)\n",
    "#Out[7]: \n",
    "#array([0.08498713, 0.05334507, 0.        , 0.        , 0.07348377,\n",
    "#       0.01111731, 0.06810687, 0.        , 0.        , 0.        ,\n",
    "#       0.        , 0.1667348 , 0.        , 0.        , 0.07852139,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "input_1:0 is both fed and fetched.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43892/1549985677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlayer_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_43892/1549985677.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlayer_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLDFT37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1444\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1446\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1447\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input_1:0 is both fed and fetched."
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([model.input], [out]) for out in outputs] # x_test: model.input\n",
    "\n",
    "x_test = np.ones((batch_size,)+K.int_shape(x_in)[1:])\n",
    "layer_outs = [func([x_test]) for func in functors]\n",
    "for i in range(len(layer_outs)):\n",
    "    print(np.array(layer_outs[i]).shape)\n",
    "#Out[10]:\n",
    "#(1, 1, 784)\n",
    "#(1, 1, 512)\n",
    "#(1, 1, 512)\n",
    "#(1, 1, 256)\n",
    "#(1, 1, 256)\n",
    "#(1, 1, 256)\n",
    "#(1, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDFT37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
