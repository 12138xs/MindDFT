{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(3171664:140535733892928,MainProcess):2024-08-29-14:36:08.639.18 [mindspore/run_check/_check_version.py:102] MindSpore version 2.2.14 and cuda version 11.8.89 does not match, CUDA version [['10.1', '11.1', '11.6']] are supported by MindSpore officially. Please refer to the installation guide for version matching information: https://www.mindspore.cn/install.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "from mindspore import nn, ops, context\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "from mindspore.train.callback import LossMonitor\n",
    "from mindspore import Tensor\n",
    "import mindspore.dataset as ds\n",
    "from mindspore.common.initializer import HeUniform\n",
    "from mindspore.train import Model\n",
    "from mindspore import save_checkpoint\n",
    "import argparse\n",
    "from datetime import date\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "os.CUDA_VISIBLE_DEVICES = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "import mindspore.numpy as mnp\n",
    "from mindspore import Tensor\n",
    "\n",
    "def get_iso_permuted_dataset(picklefile, **atm_iso):\n",
    "    dataset = []\n",
    "\n",
    "    for key, value in atm_iso.items():\n",
    "        if key == 'h_iso':\n",
    "            h_data = Tensor(np.loadtxt(value, skiprows=2, usecols=1), dtype=ms.float32)\n",
    "        elif key == 'c_iso':\n",
    "            c_data = Tensor(np.loadtxt(value, skiprows=2, usecols=1), dtype=ms.float32)\n",
    "        elif key == 'n_iso':\n",
    "            n_data = Tensor(np.loadtxt(value, skiprows=2, usecols=1), dtype=ms.float32)\n",
    "        elif key == 'o_iso':\n",
    "            o_data = Tensor(np.loadtxt(value, skiprows=2, usecols=1), dtype=ms.float32)\n",
    "        elif key == 'p_iso':\n",
    "            p_data = Tensor(np.loadtxt(value, skiprows=2, usecols=1), dtype=ms.float32)\n",
    "        else:\n",
    "            raise ValueError(\"Isolated atom type not found. Use kwargs \\\"h_iso\\\", \\\"c_iso\\\", etc.\")\n",
    "\n",
    "    with open(picklefile, \"rb\") as f:\n",
    "        molecules = pickle.load(f)\n",
    "\n",
    "    cnt = 0\n",
    "    for molecule in molecules:\n",
    "        # Load data\n",
    "        # pos = Tensor(molecule['pos'], dtype=ms.float32)\n",
    "        # z = Tensor(molecule['type'].unsqueeze(1), dtype=ms.float32)\n",
    "        # x = Tensor(molecule['onehot'], dtype=ms.float32)\n",
    "        # c = Tensor(molecule['coefficients'], dtype=ms.float32)\n",
    "        # n = Tensor(molecule['norms'], dtype=ms.float32)\n",
    "        # exp = Tensor(molecule['exponents'], dtype=ms.float32)\n",
    "        # full_c = copy.deepcopy(c)\n",
    "        # iso_c = Tensor(np.zeros_like(c.asnumpy()), dtype=ms.float32)\n",
    "        # Load from numpy arrays\n",
    "        pos = Tensor(molecule['pos'], dtype=ms.float32)\n",
    "        z = Tensor(np.expand_dims(molecule['type'], axis=1), dtype=ms.float32)\n",
    "        x = Tensor(molecule['onehot'], dtype=ms.float32)\n",
    "        c = Tensor(molecule['coefficients'], dtype=ms.float32)\n",
    "        n = Tensor(molecule['norms'], dtype=ms.float32)\n",
    "        exp = Tensor(molecule['exponents'], dtype=ms.float32)\n",
    "        full_c = ops.deepcopy(c)\n",
    "        iso_c = Tensor(np.zeros_like(c.asnumpy()), dtype=ms.float32)\n",
    "\n",
    "        # Subtract the isolated atoms\n",
    "        for atom, iso, typ in zip(c, iso_c, z):\n",
    "            typ_value = typ.asnumpy().item()\n",
    "            if typ_value == 1.0:\n",
    "                atom[:h_data.shape[0]] -= h_data\n",
    "                iso[:h_data.shape[0]] += h_data\n",
    "            elif typ_value == 6.0:\n",
    "                atom[:c_data.shape[0]] -= c_data\n",
    "                iso[:c_data.shape[0]] += c_data\n",
    "            elif typ_value == 7.0:\n",
    "                atom[:n_data.shape[0]] -= n_data\n",
    "                iso[:n_data.shape[0]] += n_data\n",
    "            elif typ_value == 8.0:\n",
    "                atom[:o_data.shape[0]] -= o_data\n",
    "                iso[:o_data.shape[0]] += o_data\n",
    "            elif typ_value == 15.0:\n",
    "                atom[:p_data.shape[0]] -= p_data\n",
    "                iso[:p_data.shape[0]] += p_data\n",
    "            else:\n",
    "                raise ValueError(\"Isolated atom type not supported!\")\n",
    "\n",
    "        pop = mnp.where(n != 0, c * 2 * math.sqrt(2) / n, n)\n",
    "\n",
    "        # Permute positions, yzx -> xyz\n",
    "        # p_pos = copy.deepcopy(pos)\n",
    "        p_pos = ops.deepcopy(pos)\n",
    "        p_pos[:, 0] = pos[:, 1]\n",
    "        p_pos[:, 1] = pos[:, 2]\n",
    "        p_pos[:, 2] = pos[:, 0]\n",
    "\n",
    "        # Create dataset dictionary\n",
    "        data_dict = {\n",
    "            'pos': p_pos,\n",
    "            'pos_orig': pos,\n",
    "            'z': z,\n",
    "            'x': x,\n",
    "            'y': pop,\n",
    "            'c': c,\n",
    "            'full_c': full_c,\n",
    "            'iso_c': iso_c,\n",
    "            'exp': exp,\n",
    "            'norm': n\n",
    "        }\n",
    "\n",
    "        dataset.append(data_dict)\n",
    "        cnt += 1\n",
    "\n",
    "    print(f\"Loaded {cnt} molecules from {picklefile}\")\n",
    "    print(f\"Loaded {len(dataset)} molecules from {picklefile}\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 molecules from ./data/water_density_testset_np_test.pkl\n",
      "Loaded 50 molecules from ./data/water_density_testset_np_test.pkl\n",
      "Loaded 50 molecules from ./data/water_density_dataset_np_test.pkl\n",
      "Loaded 50 molecules from ./data/water_density_dataset_np_test.pkl\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace()\n",
    "args.dataset = \"./data/water_density_dataset_np_test.pkl\" \n",
    "args.testset = \"./data/water_density_testset_np_test.pkl\"\n",
    "args.split   = 20\n",
    "args.epochs  = 500\n",
    "args.qm      = \"pbe0\"\n",
    "args.ldep    = False\n",
    "\n",
    "if args.qm == 'ccsd':\n",
    "    hhh = \"./data/ccsd_h_s_only_def2-universal-jfit-decontract_density.out\"\n",
    "    ooo = \"./data/ccsd_o_s_only_def2-universal-jfit-decontract_density.out\"\n",
    "else:\n",
    "    hhh = \"./data/h_s_only_def2-universal-jfit-decontract_density.out\"\n",
    "    ooo = \"./data/o_s_only_def2-universal-jfit-decontract_density.out\"\n",
    "\n",
    "test_dataset = args.testset\n",
    "num_epochs = args.epochs\n",
    "ldep_bool = args.ldep\n",
    "\n",
    "Rs = [(12, 0), (5, 1), (4, 2), (2, 3), (1, 4)]\n",
    "\n",
    "test_dataset = get_iso_permuted_dataset(args.testset, o_iso=ooo, h_iso=hhh)\n",
    "\n",
    "split = args.split\n",
    "data_file = args.dataset\n",
    "lr = 1e-2\n",
    "density_spacing = 0.1\n",
    "save_interval = 5\n",
    "model_kwargs = {\n",
    "    \"irreps_in\": 2,\n",
    "    \"irreps_hidden\": [(mul, (l, p)) for l, mul in enumerate([125, 40, 25, 15]) for p in [-1, 1]],\n",
    "    \"irreps_out\": 12,\n",
    "    \"irreps_node_attr\": None,\n",
    "    \"irreps_edge_attr\": 3,\n",
    "    \"layers\": 3,\n",
    "    \"max_radius\": 3.5,\n",
    "    \"number_of_basis\": 10,\n",
    "    \"radial_layers\": 1,\n",
    "    \"radial_neurons\": 128,\n",
    "    \"num_neighbors\": 12.2298,\n",
    "    \"num_nodes\": 24,\n",
    "    \"reduce_output\": False,\n",
    "}\n",
    "\n",
    "dataset = get_iso_permuted_dataset(data_file, o_iso=ooo, h_iso=hhh)\n",
    "random.shuffle(dataset)\n",
    "if split > len(dataset):\n",
    "    raise ValueError('Split is too large for the dataset.')\n",
    "\n",
    "b = 1\n",
    "\n",
    "def data_generator(data):\n",
    "    for d in data:\n",
    "        yield d\n",
    "\n",
    "train_loader = GeneratorDataset(lambda: data_generator(dataset[:split]), [\"train\"], shuffle=True)\n",
    "test_loader = GeneratorDataset(lambda: data_generator(test_dataset), [\"test\"], shuffle=True)\n",
    "\n",
    "train_loader = train_loader.batch(b)\n",
    "test_loader = test_loader.batch(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  20\n",
      "<mindspore.dataset.engine.datasets.BatchDataset object at 0x7fd018ce2790>\n"
     ]
    }
   ],
   "source": [
    "dataset_size = train_loader.get_dataset_size()\n",
    "print(\"Train dataset size: \", dataset_size)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[:split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n",
      "Train\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(train_loader.create_dict_iterator()):\n",
    "    print(\"Train\")\n",
    "for data in train_loader:\n",
    "    print(\"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .pkl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n"
     ]
    }
   ],
   "source": [
    "path = './data/water_density_testset.pkl'\n",
    "dataset = []\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    molecules = pickle.load(f)\n",
    "\n",
    "cnt = 0\n",
    "for data in molecules:\n",
    "    cnt += 1\n",
    "    if cnt > 50:\n",
    "        break\n",
    "    print(data.keys())\n",
    "    # dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
    "    # transform data to numpy array and save in a new .pkl file\n",
    "    data['type'] = np.array(data['type'])\n",
    "    data['pos'] = np.array(data['pos'])\n",
    "    data['onehot'] = np.array(data['onehot'])\n",
    "    data['coefficients'] = np.array(data['coefficients'])\n",
    "    data['exponents'] = np.array(data['exponents'])\n",
    "    data['norms'] = np.array(data['norms'])\n",
    "    data['rs_max'] = np.array(data['rs_max'])\n",
    "    data['energy'] = np.array(data['energy'])\n",
    "    data['forces'] = np.array(data['forces'])\n",
    "    dataset.append(data)\n",
    "\n",
    "with open('./data/water_density_testset_np_test.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
      "dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n"
     ]
    }
   ],
   "source": [
    "path = './data/water_density_dataset.pkl'\n",
    "dataset = []\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    molecules = pickle.load(f)\n",
    "\n",
    "cnt = 0\n",
    "for data in molecules:\n",
    "    cnt += 1\n",
    "    if cnt > 50:\n",
    "        break\n",
    "    print(data.keys())\n",
    "    # dict_keys(['type', 'pos', 'onehot', 'coefficients', 'exponents', 'norms', 'rs_max', 'energy', 'forces'])\n",
    "    # transform data to numpy array and save in a new .pkl file\n",
    "    data['type'] = np.array(data['type'])\n",
    "    data['pos'] = np.array(data['pos'])\n",
    "    data['onehot'] = np.array(data['onehot'])\n",
    "    data['coefficients'] = np.array(data['coefficients'])\n",
    "    data['exponents'] = np.array(data['exponents'])\n",
    "    data['norms'] = np.array(data['norms'])\n",
    "    data['rs_max'] = np.array(data['rs_max'])\n",
    "    data['energy'] = np.array(data['energy'])\n",
    "    data['forces'] = np.array(data['forces'])\n",
    "    dataset.append(data)\n",
    "\n",
    "with open('./data/water_density_dataset_np_test.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
