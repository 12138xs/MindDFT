# ===============================================================================================
# The following shows the last analyze fail log message.
# ===============================================================================================

----------------------------------------------------
- Caught exception:
----------------------------------------------------
For primitive[Shape], the input argument[shape type] must be a type of {Tensor}, but got Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/utils/check_convert_utils.cc:954 CheckSubClass

----------------------------------------------------
- The Traceback of Net Construct Code:
----------------------------------------------------
# 0 In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589
                        return grad_(fn, weights)(*args)
                               ^
# 1 In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:33
        energy_pred = model(data)
                      ^
# 2 In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:121
        x = self.relu(self.fc1(x))
                      ^
# 3 In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623
        x_shape = self.shape_op(x)
                  ^

# ===============================================================================================
# The following shows the IR when the function graphs evaluation fails to help locate the problem.
# You can search the last ------------------------> to the node which is evaluated failure.
# Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.
# ===============================================================================================

# IR entry: @after_grad_4
# Total subgraphs: 27

# Total params: 8
# Params:
%para1_args0 : <null>
%para2_args1 : <null>
%para3_fc1.weight : <Ref[Tensor[Float32]], (128, 2), ref_key=:fc1.weight>  :  has_default
%para4_fc1.bias : <Ref[Tensor[Float32]], (128), ref_key=:fc1.bias>  :  has_default
%para5_fc2.weight : <Ref[Tensor[Float32]], (64, 128), ref_key=:fc2.weight>  :  has_default
%para6_fc2.bias : <Ref[Tensor[Float32]], (64), ref_key=:fc2.bias>  :  has_default
%para7_fc3.weight : <Ref[Tensor[Float32]], (1, 64), ref_key=:fc3.weight>  :  has_default
%para8_fc3.bias : <Ref[Tensor[Float32]], (1), ref_key=:fc3.bias>  :  has_default

subgraph attr:
subgraph instance: after_grad_4 : 0x5606a10ae260
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:588/                    def after_grad(*args):/
subgraph @after_grad_4(%para1_args0, %para2_args1, %para3_fc1.weight, %para4_fc1.bias, %para5_fc2.weight, %para6_fc2.bias, %para7_fc3.weight, %para8_fc3.bias) {
  %1(CNode_12) = MakeTuple(%para1_args0, %para2_args1)
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>, <List[Tensor[Float32]*2], ListShape[(), (24, 3)]>) -> (<Tuple[Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]],List[Tensor[Float32]*2]], TupleShape(NoShape, ListShape[(), (24, 3)])>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:588/                    def after_grad(*args):/
  %2(13) = UnpackGraph(@forward_fn_3, %1)
      : (<Func, NoShape>, <Tuple[Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]],List[Tensor[Float32]*2]], TupleShape(NoShape, ListShape[(), (24, 3)])>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(CNode_14) = MakeTuple(%para3_fc1.weight, %para4_fc1.bias, %para5_fc2.weight, %para6_fc2.bias, %para7_fc3.weight, %para8_fc3.bias)
      : (<Ref[Tensor[Float32]], (128, 2)>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (64, 128)>, <Ref[Tensor[Float32]], (64)>, <Ref[Tensor[Float32]], (1, 64)>, <Ref[Tensor[Float32]], (1)>) -> (<Tuple[Ref[Tensor[Float32]]*6], TupleShape((128, 2), (128), (64, 128), (64), (1, 64), (1))>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %4(13) = S_Prim_grad(%2, %3)
      : (<Func, NoShape>, <Tuple[Ref[Tensor[Float32]]*6], TupleShape((128, 2), (128), (64, 128), (64), (1, 64), (1))>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 0
  %5(13) = UnpackCall_unpack_call(%4, %1)
      : (<Func, NoShape>, <Tuple[Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]],List[Tensor[Float32]*2]], TupleShape(NoShape, ListShape[(), (24, 3)])>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @after_grad_4:13{[0]: ValueNode<UnpackGraphPrimitive> UnpackGraph, [1]: ValueNode<FuncGraph> forward_fn_3, [2]: CNode_12}
#   2: @after_grad_4:13{[0]: ValueNode<DoSignaturePrimitive> S_Prim_grad, [1]: 13, [2]: CNode_14}
#   3: @after_grad_4:13{[0]: ValueNode<UnpackCall> MetaFuncGraph-unpack_call.15, [1]: 13, [2]: CNode_12}
#   4: @after_grad_4:CNode_16{[0]: ValueNode<Primitive> Return, [1]: 13}


subgraph attr:
core : 1
subgraph instance: UnpackCall_5 : 0x5606a0e93290
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
subgraph @UnpackCall_5(%para9_, %para10_) {
  %1(13) = TupleGetItem(%para10_7, I64(0))
      : (<Tuple[Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]],List[Tensor[Float32]*2]], TupleShape(NoShape, ListShape[(), (24, 3)])>, <Int64, NoShape>) -> (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %2(13) = TupleGetItem(%para10_7, I64(1))
      : (<Tuple[Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]],List[Tensor[Float32]*2]], TupleShape(NoShape, ListShape[(), (24, 3)])>, <Int64, NoShape>) -> (<List[Tensor[Float32]*2], ListShape[(), (24, 3)]>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 1
  %3(13) = %para9_6(%1, %2)
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>, <List[Tensor[Float32]*2], ListShape[(), (24, 3)]>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @UnpackCall_5:13{[0]: param_6, [1]: 13, [2]: 13}
#   2: @UnpackCall_5:13{[0]: ValueNode<Primitive> Return, [1]: 13}


subgraph attr:
k_graph : 1
core : 1
subgraph instance: grad_forward_fn_8 : 0x5606a0e60610
# In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:31/    def forward_fn(data, label):/
subgraph @grad_forward_fn_8 parent: [subgraph @grad_forward_fn_17](%para11_, %para12_) {
  %1(13) = $(grad_forward_fn_17):J[side_effect_propagate: I64(1)](%para-1_18)
      : (<Func, NoShape>) -> (<Func, NoShape>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/

#------------------------> 2
  %2(13) = %1(%para11_grad_forward_fn, %para12_grad_forward_fn)
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>, <List[Tensor[Float32]*2], ListShape[(), (24, 3)]>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %3(13) = TupleGetItem(%2, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %4(13) = TupleGetItem(%2, I64(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %5(13) = HyperMapPy_hyper_map[ones_like_leaf]{fn_leaf=MultitypeFuncGraph_ones_like_leaf{(NoneType), (CSRTensor), (COOTensor), (Tensor), (Func), (Number), (TypeType)}}(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %6(13) = %4(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %7(13) = TupleGetItem(%6, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %8(13) = Partial[side_effect_propagate: I64(1)](MultitypeFuncGraph_env_get{(EnvType, MapTensor), (EnvType, Tensor)}, %7)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %9(13) = HyperMap_hyper_map(%8, %para-1_19)
      : (<null>, <Tuple[Ref[Tensor[Float32]]*6], TupleShape((128, 2), (128), (64, 128), (64), (1, 64), (1))>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  %10(13) = MakeTuple(%3, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
}
# Order:
#   1: @grad_forward_fn_8:13{[0]: 13, [1]: param_grad_forward_fn, [2]: param_grad_forward_fn}
#   2: @grad_forward_fn_8:13{[0]: ValueNode<Primitive> TupleGetItem, [1]: 13, [2]: ValueNode<Int64Imm> 0}
#   3: @grad_forward_fn_8:13{[0]: ValueNode<Primitive> TupleGetItem, [1]: 13, [2]: ValueNode<Int64Imm> 1}
#   4: @grad_forward_fn_8:13{[0]: ValueNode<HyperMapPy> MetaFuncGraph-hyper_map[ones_like_leaf].20, [1]: 13}
#   5: @grad_forward_fn_8:13{[0]: 13, [1]: 13}
#   6: @grad_forward_fn_8:13{[0]: ValueNode<Primitive> TupleGetItem, [1]: 13, [2]: ValueNode<Int64Imm> 0}
#   7: @grad_forward_fn_8:13{[0]: ValueNode<Primitive> Partial, [1]: ValueNode<MultitypeFuncGraph> MetaFuncGraph-env_get.21, [2]: 13}
#   8: @grad_forward_fn_8:13{[0]: ValueNode<HyperMap> MetaFuncGraph-hyper_map.22, [1]: 13, [2]: param_19}
#   9: @grad_forward_fn_8:13{[0]: ValueNode<Primitive> MakeTuple, [1]: 13, [2]: 13}
#  10: @grad_forward_fn_8:13{[0]: ValueNode<Primitive> Return, [1]: 13}


subgraph attr:
defer_inline : 1
subgraph instance: forward_fn_3 : 0x5606a0e62130
# In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:31/    def forward_fn(data, label):/
subgraph @forward_fn_3 parent: [subgraph @after_grad_4](%para13_data, %para14_label) {

#------------------------> 3
  %1(energy_pred) = call @__main___Network_construct_9(%para13_data)
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:33/        energy_pred = model(data)/
  %2(energy_label) = S_Prim_getitem(%para14_label, I64(0))
      : (<List[Tensor[Float32]*2], ListShape[(), (24, 3)]>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:32/        energy_label, forces_label = label/
  %3(CNode_23) = S_Prim_MakeTuple()
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:39/        monomer_energy = Tensor(-76.379999960410643, ms.float32) /
  %4(CNode_24) = S_Prim_MakeTuple()
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:39/        monomer_energy = Tensor(-76.379999960410643, ms.float32) /
  %5(CNode_25) = S_Prim_make_dict(%3, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:39/        monomer_energy = Tensor(-76.379999960410643, ms.float32) /
  %6(monomer_energy) = PyInterpret[side_effect_io: Bool(1)](Script['Tensor(-76.379999960410643, ms.float32)'], InterpretedObject, %5)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:39/        monomer_energy = Tensor(-76.379999960410643, ms.float32) /
  %7(CNode_26) = S_Prim_getitem(%para13_data, "pos")
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:40/        energy_loss = loss_fn(energy_pred, (energy_label - monomer_energy * data['pos'].shape[0]/3))/
  %8(CNode_27) = getattr(%7, "shape")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:40/        energy_loss = loss_fn(energy_pred, (energy_label - monomer_energy * data['pos'].shape[0]/3))/
  %9(CNode_28) = S_Prim_getitem(%8, I64(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:40/        energy_loss = loss_fn(energy_pred, (energy_label - monomer_energy * data['pos'].shape[0]/3))/
  %10(CNode_29) = S_Prim_mul(%6, %9)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:40/        energy_loss = loss_fn(energy_pred, (energy_label - monomer_energy * data['pos'].shape[0]/3))/
  %11(CNode_30) = S_Prim_div(%10, I64(3))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:40/        energy_loss = loss_fn(energy_pred, (energy_label - monomer_energy * data['pos'].shape[0]/3))/
  %12(CNode_31) = S_Prim_sub(%2, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:40/        energy_loss = loss_fn(energy_pred, (energy_label - monomer_energy * data['pos'].shape[0]/3))/
  %13(energy_loss) = call @mindspore_nn_loss_loss_MSELoss_construct_32(%1, %12)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:40/        energy_loss = loss_fn(energy_pred, (energy_label - monomer_energy * data['pos'].shape[0]/3))/
  %14(CNode_33) = ClassType()
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:36/        forces_pred = ops.GradOperation()(energy_pred, data['pos'])/
  %15(CNode_34) = S_Prim_getitem(%para13_data, "pos")
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:36/        forces_pred = ops.GradOperation()(energy_pred, data['pos'])/
  %16(forces_pred) = %14(%1, %15)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:36/        forces_pred = ops.GradOperation()(energy_pred, data['pos'])/
  %17(forces_label) = S_Prim_getitem(%para14_label, I64(1))
      : (<List[Tensor[Float32]*2], ListShape[(), (24, 3)]>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:32/        energy_label, forces_label = label/
  %18(force_loss) = call @mindspore_nn_loss_loss_MSELoss_construct_32(%16, %17)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:41/        force_loss = loss_fn(forces_pred, forces_label)/
  %19(loss) = S_Prim_add(%13, %18)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:42/        loss = energy_loss + force_loss/
  %20(CNode_35) = S_Prim_make_list(%1, %16)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:43/        return loss, [energy_pred, forces_pred]/
  %21(CNode_36) = S_Prim_MakeTuple(%19, %20)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:43/        return loss, [energy_pred, forces_pred]/
  %22(CNode_37) = GradAux_aux_fn(%21, Bool(1))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/composite/base.py:589/                        return grad_(fn, weights)(*args)/
  Return(%22)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:43/        return loss, [energy_pred, forces_pred]/
}
# Order:
#   1: @forward_fn_3:energy_label{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_label, [2]: ValueNode<Int64Imm> 0}
#   2: @forward_fn_3:forces_label{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_label, [2]: ValueNode<Int64Imm> 1}
#   3: @forward_fn_3:energy_pred{[0]: ValueNode<FuncGraph> __main___Network_construct_9, [1]: param_data}
#   4: @forward_fn_3:CNode_33{[0]: ValueNode<ClassType> class 'mindspore.ops.composite.base.GradOperation'}
#   5: @forward_fn_3:CNode_34{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<StringImm> pos}
#   6: @forward_fn_3:forces_pred{[0]: CNode_33, [1]: energy_pred, [2]: CNode_34}
#   7: @forward_fn_3:CNode_23{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple}
#   8: @forward_fn_3:CNode_24{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple}
#   9: @forward_fn_3:CNode_25{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_dict, [1]: CNode_23, [2]: CNode_24}
#  10: @forward_fn_3:monomer_energy{[0]: ValueNode<Primitive> PyInterpret, [1]: ValueNode<Script> 'Tensor(-76.379999960410643, ms.float32)', [2]: ValueNode<InterpretedObject> PythonObject(type: <class 'dict'>, value: {'ops': <module 'mindspore.ops' from '/home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/__init__.py'>, 'Tensor': <class 'mindspore.common.tensor.Tensor'>, 'ms': <module 'mindspore' from '/home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/__init__.py'>}), [3]: CNode_25}
#  11: @forward_fn_3:CNode_26{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: param_data, [2]: ValueNode<StringImm> pos}
#  12: @forward_fn_3:CNode_27{[0]: ValueNode<Primitive> getattr, [1]: CNode_26, [2]: ValueNode<StringImm> shape}
#  13: @forward_fn_3:CNode_28{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_27, [2]: ValueNode<Int64Imm> 0}
#  14: @forward_fn_3:CNode_29{[0]: ValueNode<DoSignaturePrimitive> S_Prim_mul, [1]: monomer_energy, [2]: CNode_28}
#  15: @forward_fn_3:CNode_30{[0]: ValueNode<DoSignaturePrimitive> S_Prim_div, [1]: CNode_29, [2]: ValueNode<Int64Imm> 3}
#  16: @forward_fn_3:CNode_31{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: energy_label, [2]: CNode_30}
#  17: @forward_fn_3:energy_loss{[0]: ValueNode<FuncGraph> mindspore_nn_loss_loss_MSELoss_construct_32, [1]: energy_pred, [2]: CNode_31}
#  18: @forward_fn_3:force_loss{[0]: ValueNode<FuncGraph> mindspore_nn_loss_loss_MSELoss_construct_32, [1]: forces_pred, [2]: forces_label}
#  19: @forward_fn_3:loss{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: energy_loss, [2]: force_loss}
#  20: @forward_fn_3:CNode_35{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_list, [1]: energy_pred, [2]: forces_pred}
#  21: @forward_fn_3:CNode_36{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: loss, [2]: CNode_35}
#  22: @forward_fn_3:CNode_38{[0]: ValueNode<Primitive> Return, [1]: CNode_37}
#  23: @forward_fn_3:CNode_37{[0]: ValueNode<GradAux> MetaFuncGraph-aux_fn.39, [1]: CNode_36, [2]: ValueNode<BoolImm> true}


subgraph attr:
training : 1
subgraph instance: __main___Network_construct_9 : 0x560673c2a1b0
# In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:120/    def construct(self, x):/
subgraph @__main___Network_construct_9 parent: [subgraph @after_grad_4](%para15_x) {

#------------------------> 4
  %1(CNode_40) = call @mindspore_nn_layer_basic_Dense_construct_10(%para15_x)
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:121/        x = self.relu(self.fc1(x))/
  %2(x) = call @mindspore_nn_layer_activation_ReLU_construct_41(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:121/        x = self.relu(self.fc1(x))/
  %3(CNode_43) = call @mindspore_nn_layer_basic_Dense_construct_42(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:122/        x = self.relu(self.fc2(x))/
  %4(x) = call @mindspore_nn_layer_activation_ReLU_construct_41(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:122/        x = self.relu(self.fc2(x))/
  %5(x) = call @mindspore_nn_layer_basic_Dense_construct_44(%4)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:123/        x = self.fc3(x)/
  Return(%5)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:124/        return x/
}
# Order:
#   1: @__main___Network_construct_9:CNode_40{[0]: ValueNode<FuncGraph> mindspore_nn_layer_basic_Dense_construct_10, [1]: param_x}
#   2: @__main___Network_construct_9:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_41, [1]: CNode_40}
#   3: @__main___Network_construct_9:CNode_43{[0]: ValueNode<FuncGraph> mindspore_nn_layer_basic_Dense_construct_42, [1]: x}
#   4: @__main___Network_construct_9:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_activation_ReLU_construct_41, [1]: CNode_43}
#   5: @__main___Network_construct_9:x{[0]: ValueNode<FuncGraph> mindspore_nn_layer_basic_Dense_construct_44, [1]: x}
#   6: @__main___Network_construct_9:CNode_45{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_basic_Dense_construct_10 : 0x5606a0c6ab00
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @mindspore_nn_layer_basic_Dense_construct_10 parent: [subgraph @after_grad_4](%para16_x) {

#------------------------> 5
  %1(CNode_46) = call @L_mindspore_nn_layer_basic_Dense_construct_11(%para16_x, %para4_fc1.bias, %para3_fc1.weight)
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>, <Ref[Tensor[Float32]], (128)>, <Ref[Tensor[Float32]], (128, 2)>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
}
# Order:
#   1: @mindspore_nn_layer_basic_Dense_construct_10:CNode_46{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_basic_Dense_construct_11, [1]: param_x, [2]: param_fc1.bias, [3]: param_fc1.weight}
#   2: @mindspore_nn_layer_basic_Dense_construct_10:CNode_47{[0]: ValueNode<Primitive> Return, [1]: CNode_46}


subgraph attr:
training : 1
subgraph instance: L_mindspore_nn_layer_basic_Dense_construct_11 : 0x5606a0e21eb0
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_mindspore_nn_layer_basic_Dense_construct_11(%para17_x, %para18_, %para19_) {

#------------------------> 6
  %1(x_shape) = S_Prim_Shape(%para17_x)
      : (<Dictionary[[pos,pos_orig,z,x,y,c,full_c,exp,norm,energy,forces,],[Tensor[Float32]*11]], NoShape>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %2(CNode_48) = S_Prim_check_dense_input_shape[constexpr_prim: Bool(1)](%1, "Dense")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:624/        check_dense_input_shape(x_shape, self.cls_name)/
  %3(CNode_49) = StopGradient(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
  %4(CNode_50) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %5(CNode_51) = S_Prim_not_equal(%4, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %6(CNode_52) = Cond(%5, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %7(CNode_53) = Switch(%6, @L_✓mindspore_nn_layer_basic_Dense_construct_54, @L_✗mindspore_nn_layer_basic_Dense_construct_55)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %8(CNode_56) = %7()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
  %9(CNode_58) = call @L_↓mindspore_nn_layer_basic_Dense_construct_57(%8)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:123/        x = self.fc3(x)/
  %10(CNode_59) = Depend[side_effect_propagate: I64(1)](%9, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:123/        x = self.fc3(x)/
  Return(%10)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
}
# Order:
#   1: @L_mindspore_nn_layer_basic_Dense_construct_11:x_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_x}
#   2: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_48{[0]: ValueNode<DoSignaturePrimitive> S_Prim_check_dense_input_shape, [1]: x_shape, [2]: ValueNode<StringImm> Dense}
#   3: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_50{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: x_shape}
#   4: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_51{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_50, [2]: ValueNode<Int64Imm> 2}
#   5: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_52{[0]: ValueNode<Primitive> Cond, [1]: CNode_51, [2]: ValueNode<BoolImm> false}
#   6: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_53{[0]: ValueNode<Primitive> Switch, [1]: CNode_52, [2]: ValueNode<FuncGraph> L_✓mindspore_nn_layer_basic_Dense_construct_54, [3]: ValueNode<FuncGraph> L_✗mindspore_nn_layer_basic_Dense_construct_55}
#   7: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_56{[0]: CNode_53}
#   8: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_58{[0]: ValueNode<FuncGraph> L_↓mindspore_nn_layer_basic_Dense_construct_57, [1]: CNode_56}
#   9: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_59{[0]: ValueNode<Primitive> Depend, [1]: CNode_58, [2]: CNode_49}
#  10: @L_mindspore_nn_layer_basic_Dense_construct_11:CNode_60{[0]: ValueNode<Primitive> Return, [1]: CNode_59}


# ===============================================================================================
# The total of function graphs in evaluation stack: 7/8 (Ignored 1 internal frames).
# ===============================================================================================


# ===============================================================================================
# The rest function graphs are the following:
# ===============================================================================================
subgraph attr:
subgraph instance: mindspore_nn_loss_loss_MSELoss_construct_32 : 0x5606a0af1c00
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:315/    def construct(self, logits, labels):/
subgraph @mindspore_nn_loss_loss_MSELoss_construct_32(%para20_logits, %para21_labels) {
  %1(CNode_61) = S_Prim__check_is_tensor[constexpr_prim: Bool(1)]("logits", %para20_logits, "MSELoss")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:316/        _check_is_tensor('logits', logits, self.cls_name)/
  %2(CNode_62) = S_Prim__check_is_tensor[constexpr_prim: Bool(1)]("labels", %para21_labels, "MSELoss")
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:317/        _check_is_tensor('labels', labels, self.cls_name)/
  %3(CNode_63) = MakeTuple(%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:315/    def construct(self, logits, labels):/
  %4(CNode_64) = StopGradient(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:315/    def construct(self, logits, labels):/
  %5(CNode_65) = S_Prim_sub(%para20_logits, %para21_labels)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:318/        x = F.square(logits - labels)/
  %6(x) = call @square_66(%5)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:318/        x = F.square(logits - labels)/
  %7(CNode_68) = call @get_loss_67(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:319/        return self.get_loss(x)/
  %8(CNode_69) = Depend[side_effect_propagate: I64(1)](%7, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:319/        return self.get_loss(x)/
  Return(%8)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:319/        return self.get_loss(x)/
}
# Order:
#   1: @mindspore_nn_loss_loss_MSELoss_construct_32:CNode_61{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_is_tensor, [1]: ValueNode<StringImm> logits, [2]: param_logits, [3]: ValueNode<StringImm> MSELoss}
#   2: @mindspore_nn_loss_loss_MSELoss_construct_32:CNode_62{[0]: ValueNode<DoSignaturePrimitive> S_Prim__check_is_tensor, [1]: ValueNode<StringImm> labels, [2]: param_labels, [3]: ValueNode<StringImm> MSELoss}
#   3: @mindspore_nn_loss_loss_MSELoss_construct_32:CNode_65{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sub, [1]: param_logits, [2]: param_labels}
#   4: @mindspore_nn_loss_loss_MSELoss_construct_32:x{[0]: ValueNode<FuncGraph> square_66, [1]: CNode_65}
#   5: @mindspore_nn_loss_loss_MSELoss_construct_32:CNode_68{[0]: ValueNode<FuncGraph> get_loss_67, [1]: x}
#   6: @mindspore_nn_loss_loss_MSELoss_construct_32:CNode_70{[0]: ValueNode<Primitive> Return, [1]: CNode_69}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_basic_Dense_construct_44 : 0x5606a0be0b60
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @mindspore_nn_layer_basic_Dense_construct_44 parent: [subgraph @after_grad_4](%para22_x) {
  %1(CNode_71) = call @L_mindspore_nn_layer_basic_Dense_construct_11(%para22_x, %para8_fc3.bias, %para7_fc3.weight)
      : (<null>, <Ref[Tensor[Float32]], (1), ref_key=:fc3.bias>, <Ref[Tensor[Float32]], (1, 64), ref_key=:fc3.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
}
# Order:
#   1: @mindspore_nn_layer_basic_Dense_construct_44:CNode_71{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_basic_Dense_construct_11, [1]: param_x, [2]: param_fc3.bias, [3]: param_fc3.weight}
#   2: @mindspore_nn_layer_basic_Dense_construct_44:CNode_60{[0]: ValueNode<Primitive> Return, [1]: CNode_71}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_activation_ReLU_construct_41 : 0x5606a0564b10
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:437/    def construct(self, x):/
subgraph @mindspore_nn_layer_activation_ReLU_construct_41(%para23_x) {
  %1(CNode_72) = S_Prim_ReLU[output_names: ["output"], input_names: ["x"]](%para23_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/activation.py:438/        return self.relu(x)/
}
# Order:
#   1: @mindspore_nn_layer_activation_ReLU_construct_41:CNode_72{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReLU, [1]: param_x}
#   2: @mindspore_nn_layer_activation_ReLU_construct_41:CNode_73{[0]: ValueNode<Primitive> Return, [1]: CNode_72}


subgraph attr:
training : 1
subgraph instance: mindspore_nn_layer_basic_Dense_construct_42 : 0x5606a0d4c610
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @mindspore_nn_layer_basic_Dense_construct_42 parent: [subgraph @after_grad_4](%para24_x) {
  %1(CNode_74) = call @L_mindspore_nn_layer_basic_Dense_construct_11(%para24_x, %para6_fc2.bias, %para5_fc2.weight)
      : (<null>, <Ref[Tensor[Float32]], (64), ref_key=:fc2.bias>, <Ref[Tensor[Float32]], (64, 128), ref_key=:fc2.weight>) -> (<null>)
      #scope: (Default)
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
}
# Order:
#   1: @mindspore_nn_layer_basic_Dense_construct_42:CNode_74{[0]: ValueNode<FuncGraph> L_mindspore_nn_layer_basic_Dense_construct_11, [1]: param_x, [2]: param_fc2.bias, [3]: param_fc2.weight}
#   2: @mindspore_nn_layer_basic_Dense_construct_42:CNode_75{[0]: ValueNode<Primitive> Return, [1]: CNode_74}


subgraph attr:
subgraph instance: get_loss_67 : 0x5606a044d250
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:125/    def get_loss(self, x, weights=1.0):/
subgraph @get_loss_67(%para25_x, %para26_weights) {
  %1(CNode_77) = call @✓get_loss_76()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:143/        if self.reduce and self.average:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:143/        if self.reduce and self.average:/
}
# Order:
#   1: @get_loss_67:input_dtype{[0]: ValueNode<Primitive> getattr, [1]: param_x, [2]: ValueNode<StringImm> dtype}
#   2: @get_loss_67:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_x, [2]: ValueNode<Float> Float32}
#   3: @get_loss_67:weights{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: param_weights, [2]: ValueNode<Float> Float32}
#   4: @get_loss_67:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Mul, [1]: weights, [2]: x}
#   5: @get_loss_67:CNode_77{[0]: ValueNode<FuncGraph> ✓get_loss_76}
#   6: @get_loss_67:CNode_78{[0]: ValueNode<Primitive> Return, [1]: CNode_77}


subgraph attr:
subgraph instance: square_66 : 0x5606a0de3340
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6082/def square(input):/
subgraph @square_66(%para27_input) {
  %1(CNode_79) = S_Prim_Square[output_names: ["output"], input_names: ["input_x"]](%para27_input)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6111/    return square_(input)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:6111/    return square_(input)/
}
# Order:
#   1: @square_66:CNode_79{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Square, [1]: param_input}
#   2: @square_66:CNode_80{[0]: ValueNode<Primitive> Return, [1]: CNode_79}


subgraph attr:
subgraph instance: ✓get_loss_76 : 0x5606a0d09830
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:125/    def get_loss(self, x, weights=1.0):/
subgraph @✓get_loss_76 parent: [subgraph @get_loss_67]() {
  %1(CNode_82) = call @↓get_loss_81()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:144/            x = self.reduce_mean(x, self.get_axis(x))/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:144/            x = self.reduce_mean(x, self.get_axis(x))/
}
# Order:
#   1: @✓get_loss_76:CNode_83{[0]: ValueNode<FuncGraph> get_axis_84, [1]: x}
#   2: @✓get_loss_76:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_ReduceMean, [1]: x, [2]: CNode_83}
#   3: @✓get_loss_76:CNode_82{[0]: ValueNode<FuncGraph> ↓get_loss_81}
#   4: @✓get_loss_76:CNode_85{[0]: ValueNode<Primitive> Return, [1]: CNode_82}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_↓mindspore_nn_layer_basic_Dense_construct_57 : 0x5606a0d0bfd0
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_↓mindspore_nn_layer_basic_Dense_construct_57 parent: [subgraph @L_mindspore_nn_layer_basic_Dense_construct_11](%para28_) {
  %1(CNode_87) = call @L_✓↓mindspore_nn_layer_basic_Dense_construct_86()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:628/        if self.has_bias:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:628/        if self.has_bias:/
}
# Order:
#   1: @L_↓mindspore_nn_layer_basic_Dense_construct_57:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MatMul, [1]: param_фx, [2]: param_L_fc3.weight}
#   2: @L_↓mindspore_nn_layer_basic_Dense_construct_57:CNode_87{[0]: ValueNode<FuncGraph> L_✓↓mindspore_nn_layer_basic_Dense_construct_86}
#   3: @L_↓mindspore_nn_layer_basic_Dense_construct_57:CNode_88{[0]: ValueNode<Primitive> Return, [1]: CNode_87}


subgraph attr:
training : 1
subgraph instance: L_✓mindspore_nn_layer_basic_Dense_construct_54 : 0x5606a0e9a650
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_✓mindspore_nn_layer_basic_Dense_construct_54 parent: [subgraph @L_mindspore_nn_layer_basic_Dense_construct_11]() {
  %1(CNode_89) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %2(x_shape) = $(L_mindspore_nn_layer_basic_Dense_construct_11):S_Prim_Shape(%para17_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %3(CNode_90) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %4(CNode_91) = S_Prim_getitem(%2, %3)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %5(CNode_92) = S_Prim_MakeTuple(%1, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  %6(x) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%para17_x, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
  Return(%6)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:626/            x = self.reshape(x, (-1, x_shape[-1]))/
}
# Order:
#   1: @L_✓mindspore_nn_layer_basic_Dense_construct_54:CNode_89{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @L_✓mindspore_nn_layer_basic_Dense_construct_54:CNode_90{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   3: @L_✓mindspore_nn_layer_basic_Dense_construct_54:CNode_91{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_90}
#   4: @L_✓mindspore_nn_layer_basic_Dense_construct_54:CNode_92{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_89, [2]: CNode_91}
#   5: @L_✓mindspore_nn_layer_basic_Dense_construct_54:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: param_x, [2]: CNode_92}
#   6: @L_✓mindspore_nn_layer_basic_Dense_construct_54:CNode_93{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: L_✗mindspore_nn_layer_basic_Dense_construct_55 : 0x5606a0983d50
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_✗mindspore_nn_layer_basic_Dense_construct_55 parent: [subgraph @L_mindspore_nn_layer_basic_Dense_construct_11]() {
  Return(%para17_x)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:625/        if len(x_shape) != 2:/
}
# Order:
#   1: @L_✗mindspore_nn_layer_basic_Dense_construct_55:CNode_94{[0]: ValueNode<Primitive> Return, [1]: param_x}


subgraph attr:
subgraph instance: get_axis_84 : 0x5606a0f8c260
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:113/    def get_axis(self, x):/
subgraph @get_axis_84(%para29_x) {
  %1(shape) = call @shape_95(%para29_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:120/        shape = F.shape(x)/
  %2(length) = S_Prim_sequence_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:121/        length = F.tuple_len(shape)/
  %3(perm) = S_Prim_make_range(I64(0), %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:122/        perm = F.make_range(0, length)/
  Return(%3)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:123/        return perm/
}
# Order:
#   1: @get_axis_84:shape{[0]: ValueNode<FuncGraph> shape_95, [1]: param_x}
#   2: @get_axis_84:length{[0]: ValueNode<DoSignaturePrimitive> S_Prim_sequence_len, [1]: shape}
#   3: @get_axis_84:perm{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_range, [1]: ValueNode<Int64Imm> 0, [2]: length}
#   4: @get_axis_84:CNode_96{[0]: ValueNode<Primitive> Return, [1]: perm}


subgraph attr:
subgraph instance: ↓get_loss_81 : 0x5606a100a670
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:125/    def get_loss(self, x, weights=1.0):/
subgraph @↓get_loss_81 parent: [subgraph @✓get_loss_76]() {
  %1(CNode_98) = call @✗↓get_loss_97()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:145/        if self.reduce and not self.average:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:145/        if self.reduce and not self.average:/
}
# Order:
#   1: @↓get_loss_81:CNode_98{[0]: ValueNode<FuncGraph> ✗↓get_loss_97}
#   2: @↓get_loss_81:CNode_99{[0]: ValueNode<Primitive> Return, [1]: CNode_98}


subgraph attr:
training : 1
subgraph instance: L_✓↓mindspore_nn_layer_basic_Dense_construct_86 : 0x5606a05f83e0
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_✓↓mindspore_nn_layer_basic_Dense_construct_86 parent: [subgraph @L_↓mindspore_nn_layer_basic_Dense_construct_57]() {
  %1(CNode_101) = call @L_2↓mindspore_nn_layer_basic_Dense_construct_100()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
}
# Order:
#   1: @L_✓↓mindspore_nn_layer_basic_Dense_construct_86:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_BiasAdd, [1]: x, [2]: param_L_fc3.bias}
#   2: @L_✓↓mindspore_nn_layer_basic_Dense_construct_86:CNode_101{[0]: ValueNode<FuncGraph> L_2↓mindspore_nn_layer_basic_Dense_construct_100}
#   3: @L_✓↓mindspore_nn_layer_basic_Dense_construct_86:CNode_102{[0]: ValueNode<Primitive> Return, [1]: CNode_101}


subgraph attr:
subgraph instance: shape_95 : 0x5606a0aee1d0
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1484/def shape(input_x):/
subgraph @shape_95(%para30_input_x) {
  %1(CNode_103) = S_Prim_Shape(%para30_input_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1510/    return shape_(input_x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1510/    return shape_(input_x)/
}
# Order:
#   1: @shape_95:CNode_103{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_input_x}
#   2: @shape_95:CNode_104{[0]: ValueNode<Primitive> Return, [1]: CNode_103}


subgraph attr:
subgraph instance: ✗↓get_loss_97 : 0x5606a0d1e320
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:125/    def get_loss(self, x, weights=1.0):/
subgraph @✗↓get_loss_97 parent: [subgraph @✓get_loss_76]() {
  %1(CNode_106) = call @2↓get_loss_105()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:145/        if self.reduce and not self.average:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:145/        if self.reduce and not self.average:/
}
# Order:
#   1: @✗↓get_loss_97:CNode_106{[0]: ValueNode<FuncGraph> 2↓get_loss_105}
#   2: @✗↓get_loss_97:CNode_107{[0]: ValueNode<Primitive> Return, [1]: CNode_106}


subgraph attr:
training : 1
subgraph instance: L_2↓mindspore_nn_layer_basic_Dense_construct_100 : 0x5606a0a0c780
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_2↓mindspore_nn_layer_basic_Dense_construct_100 parent: [subgraph @L_✓↓mindspore_nn_layer_basic_Dense_construct_86]() {
  %1(CNode_109) = call @L_✗2↓mindspore_nn_layer_basic_Dense_construct_108()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
}
# Order:
#   1: @L_2↓mindspore_nn_layer_basic_Dense_construct_100:CNode_109{[0]: ValueNode<FuncGraph> L_✗2↓mindspore_nn_layer_basic_Dense_construct_108}
#   2: @L_2↓mindspore_nn_layer_basic_Dense_construct_100:CNode_110{[0]: ValueNode<Primitive> Return, [1]: CNode_109}


subgraph attr:
subgraph instance: 2↓get_loss_105 : 0x5606a0de66a0
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:125/    def get_loss(self, x, weights=1.0):/
subgraph @2↓get_loss_105 parent: [subgraph @✓get_loss_76]() {
  %1(weights) = $(get_loss_67):S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"]](%para26_weights, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:141/        weights = self.cast(weights, mstype.float32)/
  %2(x) = $(get_loss_67):S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"]](%para25_x, F32)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:140/        x = self.cast(x, mstype.float32)/
  %3(x) = $(get_loss_67):S_Prim_Mul[output_names: ["output"], input_names: ["x", "y"]](%1, %2)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:142/        x = self.mul(weights, x)/
  %4(CNode_83) = $(✓get_loss_76):call @get_axis_84(%3)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:144/            x = self.reduce_mean(x, self.get_axis(x))/
  %5(x) = $(✓get_loss_76):S_Prim_ReduceMean[output_names: ["y"], keep_dims: Bool(0), input_names: ["input_x", "axis"]](%3, %4)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:144/            x = self.reduce_mean(x, self.get_axis(x))/
  %6(input_dtype) = $(get_loss_67):getattr(%para25_x, "dtype")
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:139/        input_dtype = x.dtype/
  %7(x) = S_Prim_Cast[output_names: ["output"], input_names: ["x", "dst_type"]](%5, %6)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:147/        x = self.cast(x, input_dtype)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/loss/loss.py:148/        return x/
}
# Order:
#   1: @2↓get_loss_105:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Cast, [1]: x, [2]: input_dtype}
#   2: @2↓get_loss_105:CNode_111{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: L_✗2↓mindspore_nn_layer_basic_Dense_construct_108 : 0x5606a0f8ab10
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_✗2↓mindspore_nn_layer_basic_Dense_construct_108 parent: [subgraph @L_✓↓mindspore_nn_layer_basic_Dense_construct_86]() {
  %1(CNode_113) = call @L_3↓mindspore_nn_layer_basic_Dense_construct_112()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:630/        if self.activation_flag:/
}
# Order:
#   1: @L_✗2↓mindspore_nn_layer_basic_Dense_construct_108:CNode_113{[0]: ValueNode<FuncGraph> L_3↓mindspore_nn_layer_basic_Dense_construct_112}
#   2: @L_✗2↓mindspore_nn_layer_basic_Dense_construct_108:CNode_114{[0]: ValueNode<Primitive> Return, [1]: CNode_113}


subgraph attr:
training : 1
subgraph instance: L_3↓mindspore_nn_layer_basic_Dense_construct_112 : 0x5606a10f3b50
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_3↓mindspore_nn_layer_basic_Dense_construct_112 parent: [subgraph @L_✓↓mindspore_nn_layer_basic_Dense_construct_86]() {
  %1(x_shape) = $(L_mindspore_nn_layer_basic_Dense_construct_11):S_Prim_Shape(%para17_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %2(CNode_115) = S_Prim_inner_len(%1)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %3(CNode_116) = S_Prim_not_equal(%2, I64(2))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %4(CNode_117) = Cond(%3, Bool(0))
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %5(CNode_118) = Switch(%4, @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119, @L_✗3↓mindspore_nn_layer_basic_Dense_construct_120)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %6(CNode_121) = %5()
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
  %7(CNode_123) = call @L_4↓mindspore_nn_layer_basic_Dense_construct_122(%6)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/MindDFT/EEDM/training/train_energy_force.py:123/        x = self.fc3(x)/
  Return(%7)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
}
# Order:
#   1: @L_3↓mindspore_nn_layer_basic_Dense_construct_112:CNode_115{[0]: ValueNode<DoSignaturePrimitive> S_Prim_inner_len, [1]: x_shape}
#   2: @L_3↓mindspore_nn_layer_basic_Dense_construct_112:CNode_116{[0]: ValueNode<DoSignaturePrimitive> S_Prim_not_equal, [1]: CNode_115, [2]: ValueNode<Int64Imm> 2}
#   3: @L_3↓mindspore_nn_layer_basic_Dense_construct_112:CNode_117{[0]: ValueNode<Primitive> Cond, [1]: CNode_116, [2]: ValueNode<BoolImm> false}
#   4: @L_3↓mindspore_nn_layer_basic_Dense_construct_112:CNode_118{[0]: ValueNode<Primitive> Switch, [1]: CNode_117, [2]: ValueNode<FuncGraph> L_✓3↓mindspore_nn_layer_basic_Dense_construct_119, [3]: ValueNode<FuncGraph> L_✗3↓mindspore_nn_layer_basic_Dense_construct_120}
#   5: @L_3↓mindspore_nn_layer_basic_Dense_construct_112:CNode_121{[0]: CNode_118}
#   6: @L_3↓mindspore_nn_layer_basic_Dense_construct_112:CNode_123{[0]: ValueNode<FuncGraph> L_4↓mindspore_nn_layer_basic_Dense_construct_122, [1]: CNode_121}
#   7: @L_3↓mindspore_nn_layer_basic_Dense_construct_112:CNode_124{[0]: ValueNode<Primitive> Return, [1]: CNode_123}


subgraph attr:
after_block : 1
training : 1
subgraph instance: L_4↓mindspore_nn_layer_basic_Dense_construct_122 : 0x5606a0ca6960
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_4↓mindspore_nn_layer_basic_Dense_construct_122(%para31_) {
  Return(%para31_фx)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:635/        return x/
}
# Order:
#   1: @L_4↓mindspore_nn_layer_basic_Dense_construct_122:CNode_125{[0]: ValueNode<Primitive> Return, [1]: param_фx}


subgraph attr:
training : 1
subgraph instance: L_✓3↓mindspore_nn_layer_basic_Dense_construct_119 : 0x5606a1038b20
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119 parent: [subgraph @L_✓↓mindspore_nn_layer_basic_Dense_construct_86]() {
  %1(x) = $(L_↓mindspore_nn_layer_basic_Dense_construct_57):S_Prim_MatMul[output_names: ["output"], transpose_a: Bool(0), input_names: ["x1", "x2"], transpose_x2: Bool(1), transpose_x1: Bool(0), transpose_b: Bool(1)](%para28_фx, %para19_L_fc3.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:627/        x = self.matmul(x, self.weight)/
  %2(x) = $(L_✓↓mindspore_nn_layer_basic_Dense_construct_86):S_Prim_BiasAdd[output_names: ["output"], format: "NCHW", input_names: ["x", "b"]](%1, %para18_L_fc3.bias)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
  %3(x_shape) = $(L_mindspore_nn_layer_basic_Dense_construct_11):S_Prim_Shape(%para17_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:623/        x_shape = self.shape_op(x)/
  %4(CNode_126) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %5(CNode_127) = S_Prim_make_slice(None, %4, None)
      : (<null>, <null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %6(CNode_128) = S_Prim_getitem(%3, %5)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %7(CNode_130) = call @L_shape_129(%2)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %8(CNode_131) = S_Prim_negative(I64(1))
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %9(CNode_132) = S_Prim_getitem(%7, %8)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %10(CNode_133) = S_Prim_MakeTuple(%9)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %11(out_shape) = S_Prim_add(%6, %10)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
  %12(x) = S_Prim_Reshape[output_names: ["output"], input_names: ["tensor", "shape"]](%2, %11)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:634/            x = self.reshape(x, out_shape)/
  Return(%12)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:633/            out_shape = x_shape[:-1] + (F.shape(x)[-1],)/
}
# Order:
#   1: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_126{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   2: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_127{[0]: ValueNode<DoSignaturePrimitive> S_Prim_make_slice, [1]: ValueNode<None> None, [2]: CNode_126, [3]: ValueNode<None> None}
#   3: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_128{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: x_shape, [2]: CNode_127}
#   4: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_130{[0]: ValueNode<FuncGraph> L_shape_129, [1]: x}
#   5: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_131{[0]: ValueNode<DoSignaturePrimitive> S_Prim_negative, [1]: ValueNode<Int64Imm> 1}
#   6: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_132{[0]: ValueNode<DoSignaturePrimitive> S_Prim_getitem, [1]: CNode_130, [2]: CNode_131}
#   7: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_133{[0]: ValueNode<DoSignaturePrimitive> S_Prim_MakeTuple, [1]: CNode_132}
#   8: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:out_shape{[0]: ValueNode<DoSignaturePrimitive> S_Prim_add, [1]: CNode_128, [2]: CNode_133}
#   9: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:x{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Reshape, [1]: x, [2]: out_shape}
#  10: @L_✓3↓mindspore_nn_layer_basic_Dense_construct_119:CNode_134{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
training : 1
subgraph instance: L_✗3↓mindspore_nn_layer_basic_Dense_construct_120 : 0x5606a0c22a40
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:622/    def construct(self, x):/
subgraph @L_✗3↓mindspore_nn_layer_basic_Dense_construct_120 parent: [subgraph @L_✓↓mindspore_nn_layer_basic_Dense_construct_86]() {
  %1(x) = $(L_↓mindspore_nn_layer_basic_Dense_construct_57):S_Prim_MatMul[output_names: ["output"], transpose_a: Bool(0), input_names: ["x1", "x2"], transpose_x2: Bool(1), transpose_x1: Bool(0), transpose_b: Bool(1)](%para28_фx, %para19_L_fc3.weight)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:627/        x = self.matmul(x, self.weight)/
  %2(x) = $(L_✓↓mindspore_nn_layer_basic_Dense_construct_86):S_Prim_BiasAdd[output_names: ["output"], format: "NCHW", input_names: ["x", "b"]](%1, %para18_L_fc3.bias)
      : (<null>, <null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:629/            x = self.bias_add(x, self.bias)/
  Return(%2)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/nn/layer/basic.py:632/        if len(x_shape) != 2:/
}
# Order:
#   1: @L_✗3↓mindspore_nn_layer_basic_Dense_construct_120:CNode_135{[0]: ValueNode<Primitive> Return, [1]: x}


subgraph attr:
subgraph instance: L_shape_129 : 0x5606a0b76e40
# In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1484/def shape(input_x):/
subgraph @L_shape_129(%para32_input_x) {
  %1(CNode_103) = S_Prim_Shape(%para32_input_x)
      : (<null>) -> (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1510/    return shape_(input_x)/
  Return(%1)
      : (<null>)
      #scope: (Default)
      # In file /home/cenjianhuan/miniconda3/envs/MindDFT/lib/python3.9/site-packages/mindspore/ops/function/array_func.py:1510/    return shape_(input_x)/
}
# Order:
#   1: @L_shape_129:CNode_103{[0]: ValueNode<DoSignaturePrimitive> S_Prim_Shape, [1]: param_input_x}
#   2: @L_shape_129:CNode_104{[0]: ValueNode<Primitive> Return, [1]: CNode_103}


